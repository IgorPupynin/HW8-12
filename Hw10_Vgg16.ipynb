{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Resize the images to the VGG16 input size (32x32x3)\n",
    "def resize_images(images, size):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        resized_img = np.resize(img, size)\n",
    "        resized_images.append(resized_img)\n",
    "    return np.array(resized_images)\n",
    "\n",
    "X_train = resize_images(X_train, (32, 32))\n",
    "X_test = resize_images(X_test, (32, 32))\n",
    "\n",
    "# Add a channel for grayscale (3rd dimension) images\n",
    "X_train = np.stack((X_train,) * 3, axis=-1)\n",
    "X_test = np.stack((X_test,) * 3, axis=-1)\n",
    "\n",
    "# Normalize the images\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# Convert labels to one-hot encoding format\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGG16(weights = None, include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == \"block5_conv1\":\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.legacy.Adam(learning_rate=0.0002) # Original is 0.0001\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 279s 298ms/step - loss: 1.2155 - accuracy: 0.5268 - val_loss: 1.1930 - val_accuracy: 0.5262 - lr: 2.0000e-04\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 301s 321ms/step - loss: 1.1665 - accuracy: 0.5474 - val_loss: 1.2248 - val_accuracy: 0.5380 - lr: 2.0000e-04\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 312s 332ms/step - loss: 1.1445 - accuracy: 0.5566 - val_loss: 1.1046 - val_accuracy: 0.5859 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 317s 338ms/step - loss: 1.1185 - accuracy: 0.5701 - val_loss: 1.0775 - val_accuracy: 0.5962 - lr: 2.0000e-04\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 321s 342ms/step - loss: 1.0904 - accuracy: 0.5821 - val_loss: 0.9886 - val_accuracy: 0.6272 - lr: 2.0000e-04\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 330s 351ms/step - loss: 1.0711 - accuracy: 0.5909 - val_loss: 1.0209 - val_accuracy: 0.6106 - lr: 2.0000e-04\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 330s 351ms/step - loss: 1.0477 - accuracy: 0.6019 - val_loss: 1.1258 - val_accuracy: 0.6003 - lr: 2.0000e-04\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 336s 358ms/step - loss: 1.0253 - accuracy: 0.6103 - val_loss: 1.1079 - val_accuracy: 0.6071 - lr: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "earlyStopping = EarlyStopping(monitor = 'val_loss', patience = 3, verbose = 0, mode = 'min') \n",
    "mcp_save = ModelCheckpoint('best_weights.hdf5', save_best_only = True, monitor = 'val_loss', mode = 'min') \n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.4, patience = 7, verbose = 1, min_delta = 1e-4, mode = 'auto') # Reduz o learning_rate quando a métrica de avaliação para de melhorar\n",
    "\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=64), epochs = 10, validation_data = (X_test, y_test), callbacks = [earlyStopping, mcp_save, reduce_lr_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 26s 82ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Top       0.57      0.59      0.58      1000\n",
      "    Trousers       0.55      0.93      0.69      1000\n",
      "    Pullover       0.53      0.20      0.30      1000\n",
      "       Dress       0.46      0.59      0.52      1000\n",
      "        Coat       0.43      0.67      0.52      1000\n",
      "      Sandal       0.64      0.82      0.72      1000\n",
      "       Shirt       0.42      0.08      0.14      1000\n",
      "     Sneaker       0.83      0.65      0.73      1000\n",
      "         Bag       0.94      0.74      0.83      1000\n",
      "  Ankle boot       0.80      0.80      0.80      1000\n",
      "\n",
      "    accuracy                           0.61     10000\n",
      "   macro avg       0.62      0.61      0.58     10000\n",
      "weighted avg       0.62      0.61      0.58     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "class_names = ['Top', 'Trousers', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "report = classification_report(y_test_classes, y_pred_classes, target_names=class_names)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
